{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "protein_data = pd.read_csv('./total_e+xias.csv')\n",
    "print(type(protein_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 레이블 과 기능 으로 나누기\n",
    "y = protein_data.SC\n",
    "X = protein_data.drop ( 'xias', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "                                                     SEQ  SC\n",
      "21869  MSGQRVDVKVVMLGKEYVGKTSLVERYVHDRFLVGPYQNTIGAAFV...   0\n",
      "12323  MTRNEYIKSFNSVIDDKAIPMFGQNSVLSIINQWLNSVDASIVSST...   0\n",
      "22924  MGLFMIIAILLFQKPTVTEQLKKCWNNYVQGHCRKICRVNEVPEAL...   0\n",
      "3544   MRVKIVSKPTSQLNNIIEKIKNISTKLGFEVVDKDFDYVIAVGGDG...   1\n",
      "19379  MKAYAKKRISYMPSSPSQNVINFEEIETQKENILPLKEGRSAAALS...   0\n",
      "(23153, 2)\n",
      "\n",
      "X_test:\n",
      "\n",
      "                                                     SEQ  SC\n",
      "24600  MGLFEKYVSNLNRLLILTMVFAVICAGSTLALGVKKGIDLKGGTMV...   0\n",
      "20198  MPSSLTKTESNSDPRTNIQQVPKALDKNVTNSGNLDSTSSSTGSIT...   0\n",
      "10074  MPKFVVVTGGVMSGLGKGVVAASVGRILRARGLSVTAVKIDPYLNV...   1\n",
      "9485   MIMFQKPKGTRDFLPEEMKKRKVIEKKLRKVFDSYNFSEINTPTFE...   1\n",
      "1259   MSEKKRLHLIIADAELETVPEQILDHPAIVNYAKRRKRKPEKIILD...   1\n",
      "(9923, 2)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋  분할 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train.head())\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test.head())\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "21869    0\n",
      "12323    0\n",
      "22924    0\n",
      "3544     1\n",
      "19379    0\n",
      "Name: SC, dtype: int64\n",
      "(23153,)\n",
      "\n",
      "X_test:\n",
      "\n",
      "24600    0\n",
      "20198    0\n",
      "10074    1\n",
      "9485     1\n",
      "1259     1\n",
      "Name: SC, dtype: int64\n",
      "(9923,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nX_train:\\n\")\n",
    "print(y_train.head())\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(y_test.head())\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a =X_train.loc[:,['SEQ']].values # SEQ열에 해당하는 데이터를 모두 읽어옴 (위에서 아래로)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MGLFEKYVSNLNRLLILTMVFAVICAGSTLALGVKKGIDLKGGTMVILKTEKDPDTVTSEASRILGVSDVEAIRSSQGDVIVQVPKYLSADDVNKLARAVGGEVESVQTIGPALGRVFWESVKVAVPLALVAVSIVVFAIFRKPLLSAAVLGALALDLVDALGLMALTGVPLTLASFAGLLMIIGYAVDSNILLSMYTVKRRRVRRVDRAIADSFKTGITMVATTTAAACALFLLSMSEAMFEIAAVVIFGLIADVLNTWIFNAWVIREKIAGR']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_test_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MSGQRVDVKVVMLGKEYVGKTSLVERYVHDRFLVGPYQNTIGAAFVAKVMSVGDRTVTLGIWDTAGSERYEAMSRIYYRGAKAAIVCYDLTDSSSFERAKFWVKELRSLEEGCQIYLCGTKSDLLEEDRRRRRVDFHDVQDYADNIKAQLFETSSKTGQSVDELFQKVAEDYVSVAAFQVMTEDKGVDLGQKPNPYFYSCCHH'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = X_test.loc[:,['SEQ']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MGLFEKYVSNLNRLLILTMVFAVICAGSTLALGVKKGIDLKGGTMVILKTEKDPDTVTSEASRILGVSDVEAIRSSQGDVIVQVPKYLSADDVNKLARAVGGEVESVQTIGPALGRVFWESVKVAVPLALVAVSIVVFAIFRKPLLSAAVLGALALDLVDALGLMALTGVPLTLASFAGLLMIIGYAVDSNILLSMYTVKRRRVRRVDRAIADSFKTGITMVATTTAAACALFLLSMSEAMFEIAAVVIFGLIADVLNTWIFNAWVIREKIAGR'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = X_train.loc[:,['SC']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = X_test.loc[:,['SC']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'S', 'G', 'Q', 'R', 'V', 'D', 'V', 'K', 'V', 'V', 'M', 'L', 'G', 'K', 'E', 'Y', 'V', 'G', 'K', 'T', 'S', 'L', 'V', 'E', 'R', 'Y', 'V', 'H', 'D', 'R', 'F', 'L', 'V', 'G', 'P', 'Y', 'Q', 'N', 'T', 'I', 'G', 'A', 'A', 'F', 'V', 'A', 'K', 'V', 'M', 'S', 'V', 'G', 'D', 'R', 'T', 'V', 'T', 'L', 'G', 'I', 'W', 'D', 'T', 'A', 'G', 'S', 'E', 'R', 'Y', 'E', 'A', 'M', 'S', 'R', 'I', 'Y', 'Y', 'R', 'G', 'A', 'K', 'A', 'A', 'I', 'V', 'C', 'Y', 'D', 'L', 'T', 'D', 'S', 'S', 'S', 'F', 'E', 'R', 'A', 'K', 'F', 'W', 'V', 'K', 'E', 'L', 'R', 'S', 'L', 'E', 'E', 'G', 'C', 'Q', 'I', 'Y', 'L', 'C', 'G', 'T', 'K', 'S', 'D', 'L', 'L', 'E', 'E', 'D', 'R', 'R', 'R', 'R', 'R', 'V', 'D', 'F', 'H', 'D', 'V', 'Q', 'D', 'Y', 'A', 'D', 'N', 'I', 'K', 'A', 'Q', 'L', 'F', 'E', 'T', 'S', 'S', 'K', 'T', 'G', 'Q', 'S', 'V', 'D', 'E', 'L', 'F', 'Q', 'K', 'V', 'A', 'E', 'D', 'Y', 'V', 'S', 'V', 'A', 'A', 'F', 'Q', 'V', 'M', 'T', 'E', 'D', 'K', 'G', 'V', 'D', 'L', 'G', 'Q', 'K', 'P', 'N', 'P', 'Y', 'F', 'Y', 'S', 'C', 'C', 'H', 'H']\n",
      "23153\n"
     ]
    }
   ],
   "source": [
    "def split_data(train): # dataset ->a (X_train)\n",
    "    list_test = []\n",
    "    for i in range(train.shape[0]): #  39999,2\n",
    "        presplit = train[i] # a의 0번째 의 SEQ부터 최대크기까지(30000) 넣고 \n",
    "        list_test.append(list(presplit[0])) #한글자씩 잘라서 리스트에 저장\n",
    "\n",
    "    return list_test #모든 SEQ를 한글자씩 잘라놓은것을 리턴\n",
    "\n",
    "train = split_data(a)\n",
    "\n",
    "print(train[0])\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'G', 'L', 'F', 'E', 'K', 'Y', 'V', 'S', 'N', 'L', 'N', 'R', 'L', 'L', 'I', 'L', 'T', 'M', 'V', 'F', 'A', 'V', 'I', 'C', 'A', 'G', 'S', 'T', 'L', 'A', 'L', 'G', 'V', 'K', 'K', 'G', 'I', 'D', 'L', 'K', 'G', 'G', 'T', 'M', 'V', 'I', 'L', 'K', 'T', 'E', 'K', 'D', 'P', 'D', 'T', 'V', 'T', 'S', 'E', 'A', 'S', 'R', 'I', 'L', 'G', 'V', 'S', 'D', 'V', 'E', 'A', 'I', 'R', 'S', 'S', 'Q', 'G', 'D', 'V', 'I', 'V', 'Q', 'V', 'P', 'K', 'Y', 'L', 'S', 'A', 'D', 'D', 'V', 'N', 'K', 'L', 'A', 'R', 'A', 'V', 'G', 'G', 'E', 'V', 'E', 'S', 'V', 'Q', 'T', 'I', 'G', 'P', 'A', 'L', 'G', 'R', 'V', 'F', 'W', 'E', 'S', 'V', 'K', 'V', 'A', 'V', 'P', 'L', 'A', 'L', 'V', 'A', 'V', 'S', 'I', 'V', 'V', 'F', 'A', 'I', 'F', 'R', 'K', 'P', 'L', 'L', 'S', 'A', 'A', 'V', 'L', 'G', 'A', 'L', 'A', 'L', 'D', 'L', 'V', 'D', 'A', 'L', 'G', 'L', 'M', 'A', 'L', 'T', 'G', 'V', 'P', 'L', 'T', 'L', 'A', 'S', 'F', 'A', 'G', 'L', 'L', 'M', 'I', 'I', 'G', 'Y', 'A', 'V', 'D', 'S', 'N', 'I', 'L', 'L', 'S', 'M', 'Y', 'T', 'V', 'K', 'R', 'R', 'R', 'V', 'R', 'R', 'V', 'D', 'R', 'A', 'I', 'A', 'D', 'S', 'F', 'K', 'T', 'G', 'I', 'T', 'M', 'V', 'A', 'T', 'T', 'T', 'A', 'A', 'A', 'C', 'A', 'L', 'F', 'L', 'L', 'S', 'M', 'S', 'E', 'A', 'M', 'F', 'E', 'I', 'A', 'A', 'V', 'V', 'I', 'F', 'G', 'L', 'I', 'A', 'D', 'V', 'L', 'N', 'T', 'W', 'I', 'F', 'N', 'A', 'W', 'V', 'I', 'R', 'E', 'K', 'I', 'A', 'G', 'R']\n",
      "9923\n"
     ]
    }
   ],
   "source": [
    "def split_data(test): # dataset ->(X_test)\n",
    "    list_test = []\n",
    "    for i in range(test.shape[0]): #  39999,2\n",
    "        presplit = test[i] # b의 0번째 의 SEQ부터 최대크기까지(30000) 넣고 \n",
    "        list_test.append(list(presplit[0])) #한글자씩 잘라서 리스트에 저장\n",
    "\n",
    "    return list_test #모든 SEQ를 한글자씩 잘라놓은것을 리턴\n",
    "\n",
    "test = split_data(b)\n",
    "print(test[0])\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(split_data): # 매개변수는 tt\n",
    "    seq_list = []\n",
    "    aa_list = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X']\n",
    "\n",
    "    for t in range(len(split_data)): # 39999번 돌리고\n",
    "        embedding_matrix = np.zeros((1000, 21)) # 임베딩 매트릭스 도화지만 만들어놨음 (컨벌루션 인풋데이터로 쓰인다.)\n",
    "        test = split_data[t] # 스플릿된 SEQ의 값을 하나씩 넣어줌 \n",
    "        for i in range(len(aa_list)): # 21번만큼 반복\n",
    "            if len(test) > 1000: # 현재 스플릿된 SEQ의 값이 1000보다 크면  lengh_test에 1000을 넣어줌\n",
    "                length_test = 1000\n",
    "            else:\n",
    "                length_test = len(test) # 1000보다 아래면 그냥 그 길이를 넣어줌\n",
    "            for j in range(length_test): # lengh_test의 길이만큼 반복 (1000또는 그보다 아래)\n",
    "                if aa_list[i] == test[j]: # aa_list의 값(0번쨰부터 ~21번쨰)과  SEQ split해서 하나씩 검사\n",
    "                     #A ==    #ASDADSASADASGSADASGDSFSDDFDSFSDFSDFSDF\n",
    "                    embedding_matrix[j,i] = 1 #같을때마다 1로바꿔줌 이게 바로 임베딩 매트릭스\n",
    "        seq_list.append(embedding_matrix)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "train_data = one_hot_encoding(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(split_data): # 매개변수는 tt\n",
    "    seq_list = []\n",
    "    aa_list = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X']\n",
    "\n",
    "    for t in range(len(split_data)): # 39999번 돌리고\n",
    "        embedding_matrix = np.zeros((1000, 21)) # 임베딩 매트릭스 도화지만 만들어놨음 (컨벌루션 인풋데이터로 쓰인다.)\n",
    "        test = split_data[t] # 스플릿된 SEQ의 값을 하나씩 넣어줌 \n",
    "        for i in range(len(aa_list)): # 21번만큼 반복\n",
    "            if len(test) > 1000: # 현재 스플릿된 SEQ의 값이 1000보다 크면  lengh_test에 1000을 넣어줌\n",
    "                length_test = 1000\n",
    "            else:\n",
    "                length_test = len(test) # 1000보다 아래면 그냥 그 길이를 넣어줌\n",
    "            for j in range(length_test): # lengh_test의 길이만큼 반복 (1000또는 그보다 아래)\n",
    "                if aa_list[i] == test[j]: # aa_list의 값(0번쨰부터 ~21번쨰)과  SEQ split해서 하나씩 검사\n",
    "                     #A ==    #ASDADSASADASGSADASGDSFSDDFDSFSDFSDFSDF\n",
    "                    embedding_matrix[j,i] = 1 #같을때마다 1로바꿔줌 이게 바로 임베딩 매트릭스\n",
    "        seq_list.append(embedding_matrix)\n",
    "        \n",
    "    return seq_list\n",
    "\n",
    "test_data = one_hot_encoding(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "class CNN1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 항상 torch.nn.Module을 상속받고 시작\n",
    "        super(CNN1, self).__init__()\n",
    "        conv1 = nn.Conv2d(1, 128, kernel_size = (4,21), stride = 1) # 6@24*24\n",
    "        batch_conv1 = nn.BatchNorm2d(128)\n",
    "        pool1 = nn.MaxPool2d(kernel_size=(997,1)) # 6@12*a12\n",
    "      \n",
    "        self.CNN1_module = nn.Sequential(\n",
    "            conv1,\n",
    "            batch_conv1,\n",
    "            nn.ReLU(),\n",
    "            pool1\n",
    "        )\n",
    "        \n",
    "        conv2 = nn.Conv2d(1, 128, kernel_size = (8,21), stride = 1) # 6@24*24\n",
    "        batch_conv2 = nn.BatchNorm2d(128)\n",
    "        pool2 = nn.MaxPool2d(kernel_size=(993,1)) # 6@12*a12\n",
    "        \n",
    "        self.CNN2_module = nn.Sequential(\n",
    "            conv2,\n",
    "            batch_conv2,\n",
    "            nn.ReLU(),\n",
    "            pool2\n",
    "        )\n",
    "        \n",
    "        conv3 = nn.Conv2d(1, 128, kernel_size = (16,21), stride = 1) # 6@24*24\n",
    "        batch_conv3 = nn.BatchNorm2d(128)\n",
    "        pool3 = nn.MaxPool2d(kernel_size=(985,1)) # 6@12*a12\n",
    "        \n",
    "        self.CNN3_module = nn.Sequential(\n",
    "            conv3,\n",
    "            batch_conv3,\n",
    "            nn.ReLU(),\n",
    "            pool3\n",
    "        )\n",
    "        \n",
    "        fc1 = nn.Linear(128, 512)\n",
    "        fc2 = nn.Linear(512, 512)\n",
    "        fc3 = nn.Linear(512, 2)\n",
    "        # activation ReLU\n",
    "\n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            nn.ReLU(),\n",
    "            fc2,\n",
    "            nn.ReLU(),\n",
    "            fc3,\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        if use_cuda:\n",
    "            self.CNN1_module = self.CNN1_module.cuda()\n",
    "            self.CNN2_module = self.CNN2_module.cuda()\n",
    "            self.CNN3_module = self.CNN3_module.cuda()\n",
    "            self.fc_module = self.fc_module.cuda()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out1 = self.CNN1_module(x) # @16*4*4\n",
    "        out2 = self.CNN2_module(x) # @16*4*4\n",
    "        out3 = self.CNN3_module(x) # @16*4*4\n",
    "        # make linear\n",
    "        out = out1+out2+out3\n",
    "        dim = 1\n",
    "        \n",
    "        for d in out.size()[1:]: #16, 4, 4\n",
    "            dim = dim * d\n",
    "        \n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc_module(out)\n",
    "        return out\n",
    "    \n",
    "class CNN2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 항상 torch.nn.Module을 상속받고 시작\n",
    "        super(CNN2, self).__init__()\n",
    "\n",
    "        conv2 = nn.Conv2d(1, 128, kernel_size = (8, 21), stride = 1) # 6@24*24\n",
    "        pool2 = nn.MaxPool2d(kernel_size=(993,1)) # 6@12*a12\n",
    "        \n",
    "        self.CNN2_module = nn.Sequential(\n",
    "            conv2,\n",
    "            nn.ReLU(),\n",
    "            pool2\n",
    "        )\n",
    "        \n",
    "        fc1 = nn.Linear(128, 512)\n",
    "        fc2 = nn.Linear(512, 2)\n",
    "        # activation ReLU\n",
    "\n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            nn.ReLU(),\n",
    "            fc2,\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_list = []\n",
    "        out = self.conv2_module(x) # @16*4*4\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]: #16, 4, 4\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc_module(out)\n",
    "        return out\n",
    "    \n",
    "class CNN3(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 항상 torch.nn.Module을 상속받고 시작\n",
    "        super(CNN1, self).__init__()\n",
    "\n",
    "        conv3 = nn.Conv2d(1, 128, kernel_size = (16, 21), stride = 1) # 6@24*24\n",
    "        pool3 = nn.MaxPool2d(kernel_size=(985,1)) # 6@12*a12\n",
    "        \n",
    "        self.CNN_module = nn.Sequential(\n",
    "            conv3,\n",
    "            nn.ReLU(),\n",
    "            pool3\n",
    "        )\n",
    "        \n",
    "        fc1 = nn.Linear(128, 512)\n",
    "        fc2 = nn.Linear(512, 2)\n",
    "        # activation ReLU\n",
    "\n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            nn.ReLU(),\n",
    "            fc2,\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_list = []\n",
    "        out = self.CNN3_module(x) # @16*4*4\n",
    "        # make linear\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]: #16, 4, 4\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc_module(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    visline(X=num,\n",
    "           Y=loss_value,\n",
    "           win = loss_plot,\n",
    "           update='append'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_plt = vis.line([[0.,0.]], opts=dict(title='loss_tracker', legend=['loss_train','loss_test'], showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 0.297542957265865\n"
     ]
    }
   ],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "# backpropagation method\n",
    "learning_rate = 0.00001\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "# hyper-parameters\n",
    "epochs = 3\n",
    "\n",
    "history = {\n",
    "    'train_loss' : []\n",
    "}\n",
    "\n",
    "for e in range(1):\n",
    "    running_loss = 0\n",
    "    t = 0\n",
    "    for i in range(len(train_data)):\n",
    "            cnn.eval()\n",
    "            index_value = 0\n",
    "            tqwe = float(c[i])\n",
    "            \n",
    "            if tqwe == 1:\n",
    "                index_value = torch.FloatTensor([[0.0,tqwe]])\n",
    "            else:\n",
    "                index_value = torch.FloatTensor([[tqwe,0.0]])\n",
    "            #index_value = torch.LongTensor(index_data[i])\n",
    "            data = torch.from_numpy(train_data[t]).float()\n",
    "            data = data.view(1,1,1000,21)\n",
    "            \n",
    "            if use_cuda:\n",
    "                data = data.cuda()\n",
    "                index_value =index_value.cuda()\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            model_output = cnn(data)\n",
    "            loss_fn = nn.BCELoss()\n",
    "            loss = loss_fn(model_output, index_value)\n",
    "            \n",
    "            #loss = criterion(model_output,index_value)\n",
    "            loss.backward()\n",
    "            # weight update\n",
    "            optimizer.step()\n",
    "            t = t + 1 \n",
    "            running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e+1, running_loss/len(train_data)))\n",
    "                \n",
    "    history['train_loss'].append(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(range(epochs), history['train_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 33.36\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for y in range(len(test_data)):\n",
    "        data = torch.from_numpy(test_data[y]).float()\n",
    "        data = data.view(1,1,1000,21)\n",
    "        outputs = cnn(data)\n",
    "        index_value = torch.LongTensor(d[y])\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "         #print(predicted)\n",
    "        correct += (predicted == index_value).sum().item()\n",
    "    print('Accuracy : %.2f'%(float((100 * correct) / len(test_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "# backpropagation method\n",
    "learning_rate = 0.00001\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "# hyper-parameters\n",
    "epochs = 1\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    t = 0\n",
    "    for i in range(len(test_data)):\n",
    "            cnn.eval()\n",
    "\n",
    "            tqwe = float(d[i])\n",
    "            \n",
    "            if tqwe == 1:\n",
    "                index_value = torch.FloatTensor([0.0,tqwe])\n",
    "            else:\n",
    "                index_value = torch.FloatTensor([tqwe,0.0])\n",
    "            #index_value = torch.LongTensor(index_data[i])\n",
    "            data = torch.from_numpy(test_data[t]).float()\n",
    "            data = data.view(1,1,1000,21)\n",
    "            optimizer.zero_grad()\n",
    "            model_output = cnn(data)\n",
    "            loss_fn = nn.BCELoss()\n",
    "            loss = loss_fn(model_output, index_value)\n",
    "            \n",
    "            #loss = criterion(model_output,index_value)\n",
    "            loss.backward()\n",
    "            # weight update\n",
    "            optimizer.step()\n",
    "            t = t + 1 \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e+1, running_loss/len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시킨 모델을 save (쓸 때마다 다시 학습시킬 순 없다!)\n",
    "torch.save(net.state_dict(), \"./model/model.pth\")\n",
    "new_net = CNN()\n",
    "new_net.load_state_dict(torch.load('./model/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_set = DataLoader(dataset = test_data, batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1ae578b2a48>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
